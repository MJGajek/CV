{
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import unittest\n",
        "from run import setup\n",
        "from interface import handle_query\n",
        "import os"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "56slqpfY4zZv",
        "outputId": "9f1be71e-4763-4724-964d-019f382dcbd7"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sentence_transformers/cross_encoder/CrossEncoder.py:13: TqdmExperimentalWarning: Using `tqdm.autonotebook.tqdm` in notebook mode. Use `tqdm.tqdm` instead to force console mode (e.g. in jupyter console)\n",
            "  from tqdm.autonotebook import tqdm, trange\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class TestRunIntegration(unittest.TestCase):\n",
        "\n",
        "    @classmethod\n",
        "    def setUpClass(cls):\n",
        "        # Initialize the components by calling the setup function from run.py\n",
        "        cls.index, cls.metadata, cls.retriever_model, cls.model, cls.tokenizer, cls.streamer = setup()\n",
        "\n",
        "        # Define retrieval and generation parameters as used in run.py\n",
        "        cls.retriever_params = {\n",
        "            \"initial_top_k\": 30,\n",
        "            \"final_top_k\": 2,\n",
        "            \"similarity_threshold\": 1.1\n",
        "        }\n",
        "        cls.generator_params = {\n",
        "            \"max_new_tokens\": 120,\n",
        "            \"temperature\": 0.13,\n",
        "            \"repetition_penalty\": 1.2,\n",
        "            \"top_p\": 0.96,\n",
        "            \"do_sample\": False\n",
        "        }\n",
        "\n",
        "    def test_handle_query_with_relevant_context(self):\n",
        "        \"\"\"Test the pipeline with a query expected to have relevant context in the metadata.\"\"\"\n",
        "        query = \"What was discussed about ethics in AI?\"\n",
        "\n",
        "        # Pass the query through handle_query, simulating the chatbot behavior\n",
        "        response = handle_query(\n",
        "            query=query,\n",
        "            index=self.index,\n",
        "            metadata=self.metadata,\n",
        "            retriever_model=self.retriever_model,\n",
        "            model=self.model,\n",
        "            tokenizer=self.tokenizer,\n",
        "            streamer=self.streamer,\n",
        "            retriever_params=self.retriever_params,\n",
        "            generator_params=self.generator_params\n",
        "        )\n",
        "\n",
        "        # Assertions to check that the response is well-formed and relevant\n",
        "        self.assertIsInstance(response, str, \"Response should be a string.\")\n",
        "        self.assertGreater(len(response), 0, \"Response should not be empty.\")\n",
        "        self.assertIn(\"ethics\", response.lower(), \"Response should mention 'ethics' if relevant context is found.\")\n",
        "\n",
        "    def test_handle_query_with_no_relevant_context(self):\n",
        "        \"\"\"Test the pipeline with a query expected to have no relevant context in the metadata.\"\"\"\n",
        "        query = \"Tell me about a topic not covered in the conference.\"\n",
        "\n",
        "        # Pass the query through handle_query, expecting no relevant context\n",
        "        response = handle_query(\n",
        "            query=query,\n",
        "            index=self.index,\n",
        "            metadata=self.metadata,\n",
        "            retriever_model=self.retriever_model,\n",
        "            model=self.model,\n",
        "            tokenizer=self.tokenizer,\n",
        "            streamer=self.streamer,\n",
        "            retriever_params=self.retriever_params,\n",
        "            generator_params=self.generator_params\n",
        "        )\n",
        "\n",
        "        # Assertions to check that the response indicates no relevant context was found\n",
        "        self.assertIsInstance(response, str, \"Response should be a string.\")\n",
        "        self.assertIn(\"Temat nie wydaje się być poruszany\", response, \"Expected message when no relevant context is found.\")\n",
        "\n"
      ],
      "metadata": {
        "id": "3HvP4iIU4zdo"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "if __name__ == '__main__':\n",
        "    unittest.main(argv=['first-arg-is-ignored'], exit=False)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "y_q3bmIA4zll",
        "outputId": "20973671-64b8-4400-eb76-ba75fe6ad622"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "FAISS index loaded successfully.\n",
            "Metadata loaded successfully.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Retriever model initialized successfully.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            ".F\n",
            "======================================================================\n",
            "FAIL: test_handle_query_with_relevant_context (__main__.TestRunIntegration)\n",
            "Test the pipeline with a query expected to have relevant context in the metadata.\n",
            "----------------------------------------------------------------------\n",
            "Traceback (most recent call last):\n",
            "  File \"<ipython-input-2-e4254e6f6e7a>\", line 42, in test_handle_query_with_relevant_context\n",
            "    self.assertIn(\"ethics\", response.lower(), \"Response should mention 'ethics' if relevant context is found.\")\n",
            "AssertionError: 'ethics' not found in 'temat nie wydaje się być poruszany na tej konferencji.' : Response should mention 'ethics' if relevant context is found.\n",
            "\n",
            "----------------------------------------------------------------------\n",
            "Ran 2 tests in 9.333s\n",
            "\n",
            "FAILED (failures=1)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Tell me about a topic not covered in the conference.\n",
            "Retrieved in 1731441018.0714 seconds\n",
            "Average similarity distance (initial top-k): 1.6245\n",
            "Average similarity distance (final top-k): 1.4727\n",
            "Results count after filtering: 2\n",
            "\n",
            "Nie znaleziono odpowiedniego kontekstu: Temat nie był poruszany na konferencji.\n",
            "Query: What was discussed about ethics in AI?\n",
            "Retrieved in 1731441018.0852 seconds\n",
            "Average similarity distance (initial top-k): 1.6854\n",
            "Average similarity distance (final top-k): 1.5040\n",
            "Results count after filtering: 2\n",
            "\n",
            "Nie znaleziono odpowiedniego kontekstu: Temat nie był poruszany na konferencji.\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "A100",
      "machine_shape": "hm",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}